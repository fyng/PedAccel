{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Metrics most correlated to SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import sys\n",
    "sys.path.append(\"..\") #give this script access to all modules in parent directory\n",
    "from pathlib import Path\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import kendalltau\n",
    "import tsfel\n",
    "from operator import itemgetter\n",
    "import os\n",
    "from Data_Cleaning import preprocess\n",
    "import Actigraph_Metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal parameters\n",
    "freq = 100 #signal is 100hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load All Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to Load data of interest\n",
    "data_dir = 'C:/Users/sidha/OneDrive/Sid Stuff/PROJECTS/iMEDS Design Team/Data Analysis/PedAccel/data_analysis/PythonPipeline/PatientData'\n",
    "\n",
    "# data_dir = r'C:\\Users\\jakes\\Documents\\DT 6 Analysis\\PythonCode\\PedAccel\\data_analysis\\PythonPipeline\\PatientData'\n",
    "\n",
    "\n",
    "#set params\n",
    "slice_size_min = 15\n",
    "lead_time = 10\n",
    "window_size = 100 #100 is 1 second worth of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Change for data of interest\n",
    "#preprocess.load_and_segment_data(data_dir, slice_size_min, lead_time) #take sbs csv and accel gt3x to create a .mat file with vector magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Most correlated features for some signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is no error handling in place, the .mat file must exist\n",
    "for patient in os.listdir(data_dir):\n",
    "        # filter out non-directories\n",
    "        patient_dir = os.path.join(data_dir, patient)\n",
    "        if os.path.isdir(patient_dir):\n",
    "            data_filepath_accel = os.path.join(patient_dir, f'{patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN.mat')           \n",
    "            data_filepath_vitals = os.path.join(patient_dir, f'{patient}_SICKBAY_{lead_time}MIN_{slice_size_min - lead_time}MIN.mat')\n",
    "\n",
    " \n",
    "        accel_data = loadmat(data_filepath_accel)\n",
    "        x_mag = accel_data[\"x_mag\"]\n",
    "        accel_SBS = accel_data[\"sbs\"]\n",
    "        \n",
    "        vitals_data = loadmat(data_filepath_vitals)\n",
    "        hr = vitals_data['heart_rate']\n",
    "        SpO2 = vitals_data['SpO2']\n",
    "        rr = vitals_data['respiratory_rate']\n",
    "        bps = vitals_data['blood_pressure_systolic']\n",
    "        bpm = vitals_data['blood_pressure_mean']\n",
    "        bpd = vitals_data['blood_pressure_diastolic']\n",
    "        vitals_SBS = vitals_data['sbs']\n",
    "\n",
    "\n",
    "        fs = .5\n",
    "\n",
    "        # Generate configuration file for feature extraction\n",
    "        cfg_file = tsfel.get_features_by_domain()\n",
    "\n",
    "        # Extract features and restructure data\n",
    "        features_list = []\n",
    "        sbs_list = []\n",
    "        signal_list = [hr, SpO2, rr, bps, bpm, bpd]\n",
    "        signal_names = ['hr', 'SpO2', 'rr', 'bps', 'bpm', 'bpd', 'vitals_SBS']\n",
    "        count = 0\n",
    "        for signal in signal_list: \n",
    "            #Can change the signal            \n",
    "            for i in range(len(signal.squeeze())):\n",
    "                #signal = Actigraph_Metrics.VecMag_MAD(x_mag[i,:],100)\n",
    "                sbs_list.append(vitals_SBS.squeeze()[i])\n",
    "                features = tsfel.time_series_features_extractor(cfg_file, signal[i], fs, verbose=0)\n",
    "                features_list.append(features)\n",
    "            print(len(features_list[0]))\n",
    "\n",
    "            #list comprehension for column names\n",
    "            columns = [col for col in list(features_list[0])]\n",
    "            # Convert features and SBS scores to DataFrame\n",
    "            features_array = np.array(features_list).reshape(-1, len(columns)) #may need to change 389\n",
    "            df_features = pd.DataFrame(features_array)\n",
    "\n",
    "            df_features.columns = columns\n",
    "\n",
    "            #Pearson Correlation Coefficient\n",
    "            CCoeff = []\n",
    "            for i in columns:\n",
    "                y = sbs_list\n",
    "                myX = list(df_features[i])\n",
    "                nan_indices = [i for i, x in enumerate(myX) if math.isnan(x)]\n",
    "                myX = [x for x in myX if not math.isnan(x)]\n",
    "                cleaned_y = [val for idx, val in enumerate(y) if idx not in nan_indices]\n",
    "\n",
    "                corr, _ = pearsonr(cleaned_y, myX)\n",
    "                CCoeff.append(np.abs(corr))\n",
    "            my_dict = dict(zip(list(columns), list(CCoeff)))\n",
    "\n",
    "            # functional\n",
    "            clean_dict = filter(lambda k: not math.isnan(my_dict[k]), my_dict)\n",
    "            # dict comprehension\n",
    "            clean_dict = {k: my_dict[k] for k in my_dict if not math.isnan(my_dict[k])}\n",
    "\n",
    "            #Retrieve N features with best correlation coefficient  \n",
    "            # Initialize N\n",
    "            N = 5\n",
    "            \n",
    "            # N largest values in dictionary\n",
    "            # Using sorted() + itemgetter() + items()\n",
    "            res = dict(sorted(clean_dict.items(), key=itemgetter(1), reverse=True)[:N])\n",
    "\n",
    "            # printing result\n",
    "            print(\"The top N value pairs are \" + str(res))\n",
    "\n",
    "            #Plot a histogram\n",
    "            y = list(res.keys())\n",
    "            x = list(res.values()) #price\n",
    "            \n",
    "            if len(x) != 0:\n",
    "                # Figure Size\n",
    "                fig, ax = plt.subplots(figsize =(10 ,5))\n",
    "                \n",
    "                # Horizontal Bar Plot\n",
    "                ax.barh(y, x)\n",
    "                \n",
    "                # Remove axes splines\n",
    "                for s in ['top', 'bottom', 'left', 'right']:\n",
    "                    ax.spines[s].set_visible(False)\n",
    "                \n",
    "                # Remove x, y Ticks\n",
    "                ax.xaxis.set_ticks_position('none')\n",
    "                ax.yaxis.set_ticks_position('none')\n",
    "                \n",
    "                # Add padding between axes and labels\n",
    "                ax.xaxis.set_tick_params(pad = 5)\n",
    "                ax.yaxis.set_tick_params(pad = 10)\n",
    "                \n",
    "                # Add x, y gridlines\n",
    "                ax.grid(color ='grey',\n",
    "                        linestyle ='-.', linewidth = 0.5,\n",
    "                        alpha = 0.2)\n",
    "                \n",
    "                # Show top values \n",
    "                ax.invert_yaxis()\n",
    "\n",
    "                #set x axis range\n",
    "                ax.set_xlim([.8*min(x),1.1*max(x)])\n",
    "            \n",
    "                # Add Plot Title\n",
    "                ax.set_title(f'Correlation between top features and SBS for\\n {patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN {signal_names[count]})',\n",
    "                            loc ='left', )\n",
    "                \n",
    "                # Show Plot\n",
    "\n",
    "                plt.show()\n",
    "                count= count+1\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DT6Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
